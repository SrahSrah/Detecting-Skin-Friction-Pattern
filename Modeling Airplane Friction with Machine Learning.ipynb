{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Airplane Friction with Machine Learning\n",
    "\n",
    "## Abstract: \n",
    "\n",
    "I create a Haar classifier with openCV to identify oil fringes on a model airplane at NASA. I then use a convoluted neural network to identify key points on each fringe to determine the skin friction across the airplane's wing, tail and fuseladge. \n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "#### I)     Introduction: Finding Friction with Oil Droplets and Math\n",
    "#### II)    Creating a Haar Classifier from scratch with openCV\n",
    "#### III)   Idk my bff jill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction: Finding Friction with Oil Droplets and Math\n",
    "\n",
    "My first project at NASA involved determing the skin friction on a 3% scale model of a standard airplane. Skin friction on airplane wings account for over 50% of drag on modern airplanes. By understanding how friction exerts itself across a plane's wing and tail, we can make more fuel efficient airplanes. \n",
    "\n",
    "We measure the skin friction by applying droplets of oil onto the wing, tail, and fuseladge. The model is then subject to winds of 160 ft/sec for fifteen minutes. At the end of the run, the oil droplets look like this:\n",
    "\n",
    "*image of single fringe*\n",
    "\n",
    "Each oil droplet produced a \"fringe\". We can then look at the change in light intentsity between the first and second layer of each fringe to determine the friction at that location. However, this becomes a problem when your pictures look like this:\n",
    "\n",
    "\n",
    "*image of all fringes*\n",
    "\n",
    "So to glean the magnitude of friction from a single picture, we must manually identify each fringe, and manually input the two target points of each. The software can then determine the *however skin friction works*. The two target point on a fringe are shown below:\n",
    "\n",
    "*Image of fringe with two target points*\n",
    "\n",
    "\n",
    "With hundreds of pictures to process, analyzing the data took *several utterly mind-numbing weeks*. To save someone else from this fate in the future, I decided to take a crack at simplyfying the process by creating a machine learning algorithim to:\n",
    "\n",
    "            1. Isolate Fringes in an Image\n",
    "            2. Detect the two target points of each fringe\n",
    "\n",
    "Do this will take several steps, and a lot of editing of this jupyter notebook, but I can do it, and I shall! Don't worry too much about formatting/tone yet, just get it out there!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating Fringes in an Image: \n",
    "### Creating a Haar Classifier from scratch with Open CV\n",
    "\n",
    "1) Create data set:\n",
    "After five minutes of research, it became clear that the first thing I would need to do was curate my own data set. This, unfortunely also involved a few mind numbing hours, but hopefully I can give you a few tips to make the process as smooth as possible.\n",
    "\n",
    "To create your data set you need two things:\n",
    "1) X Number of Positive Images, scaled to size MxN\n",
    "2) Y Number of Negative Images, scaled to size MxN where Y >> X\n",
    "\n",
    "The exact values of X, Y, M, and N are a fuction of how accurate you'd like your Haar classifier to be and your available computing speed. Because our target (fringes) are a relatively easy pattern to identify, I will use 100 positive images and 600 negative images scaled to size MxN.\n",
    "\n",
    "To build a Haar classifier with OpenCV, you \n",
    "\n",
    "#### Curating your Positive Image Dataset\n",
    "\n",
    "\n",
    "#### Curating your Negative Image Dataset \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# This function grabs images of planes from image-net.org to use \n",
    "# as our negative data set. It converts all images to grayscale and\n",
    "# resizes to 100x100\n",
    "\n",
    "def store_raw_images():\n",
    "    \n",
    "    neg_images_link = \"http://image-net.org/api/text/imagenet.synset.geturls?wnid=n02690373\"\n",
    "    neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
    "    \n",
    "    #create directory if one does not exist\n",
    "    if not os.path.exists('neg'):\n",
    "        os.makedirs('neg')\n",
    "    \n",
    "    #split url\n",
    "    pic_num = 1\n",
    "    for i in neg_image_urls.split('\\n'):\n",
    "        try:\n",
    "            #Grab url and name image\n",
    "            urllib.request.urlretrieve(i, \"neg/\" + str(pic_num) + \".jpg\")\n",
    "            \n",
    "            #Convert to grayscale\n",
    "            img = cv2.imread(\"neg/\" + str(pic_num) + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            #Resize image to 200x200\n",
    "            resized_img = cv2.resize(img, (200,200))\n",
    "            \n",
    "            #Save image\n",
    "            cv2.imwrite(\"neg/\" + str(pic_num) + \".jpg\", resized_img)\n",
    "            \n",
    "            pic_num += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Image failed to upload\")\n",
    "    \n",
    "    print(\"store_raw_images complete!\")\n",
    "store_raw_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_false_negs complete\n"
     ]
    }
   ],
   "source": [
    "#Remove false negatives (Flicker's \"image unavailable\" image) from neg\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_false_negs():\n",
    "    for file_type in ['neg']:\n",
    "        for img in os.listdir(file_type):\n",
    "            for false_img in os.listdir('false negs'):\n",
    "                try:\n",
    "                    current_image_path = str(file_type) + '/' + str(img)\n",
    "                    false_neg = cv2.imread(\"false negs/\" + str(false_img))\n",
    "                    current_img = cv2.imread(current_image_path)\n",
    "            \n",
    "                    if false_neg.shape == current_img.shape and not(np.bitwise_xor(false_neg, current_img).any()):\n",
    "                        os.remove(current_image_path)\n",
    "                        print(current_image_path + \" was removed\")\n",
    "                        \n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                    \n",
    "    print(\"remove_false_negs complete!\")\n",
    "    \n",
    "remove_false_negs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created\n"
     ]
    }
   ],
   "source": [
    "#Define description files\n",
    "import os\n",
    "\n",
    "#Creates a text file called \"bg.txt\" that contains file paths of all neg images\n",
    "def create_neg_descriptions():\n",
    "    \n",
    "    for file_type in [\"neg\"]:\n",
    "        for img in os.listdir(file_type):\n",
    "            if file_type == 'neg':\n",
    "                line = file_type + '/' + img + '\\n'\n",
    "                with open('bg.txt', 'a') as f:\n",
    "                    f.write(line)\n",
    "    print(\"File bg.txt created\")\n",
    "            \n",
    "create_neg_descriptions()            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/travis/miniconda3/conda-bld/opencv_1490902680113/work/opencv-3.2.0/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23894e096bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Positive Samples Prepared\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprepare_pos_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-23894e096bf3>\u001b[0m in \u001b[0;36mprepare_pos_samples\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#Resize image to 60x160\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mresized_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/travis/miniconda3/conda-bld/opencv_1490902680113/work/opencv-3.2.0/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "#Generate positive samples based on 100 starting samples\n",
    "def generate_pos_samples():\n",
    "    \n",
    "    pic_num = 0\n",
    "    for file_type in [\"pos initial\"]:\n",
    "        for img in os.listdir(file_type):\n",
    "            \n",
    "            #Convert to grayscale\n",
    "            gray_img = cv2.imread(\"pos initial/\" + str(img), cv2.IMREAD_GRAYSCALE)\n",
    "         \n",
    "            #Resize image to 60x160\n",
    "            resized_img = cv2.resize(gray_img, (60,160))\n",
    "            \n",
    "            \n",
    "            #Save image\n",
    "            cv2.imwrite(\"pos final/\" + str(pic_num) + \".jpg\", resized_img)\n",
    "            \n",
    "            pic_num += 1\n",
    "                \n",
    "    \n",
    "    print(\"Positive Samples Prepared\")\n",
    "    \n",
    "prepare_pos_samples()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resizing completed\n"
     ]
    }
   ],
   "source": [
    "pic_num = 0\n",
    "for file_type in [\"neg\"]:\n",
    "        for img in os.listdir(file_type):\n",
    "            \n",
    "            #Convert to grayscale\n",
    "            gray_img = cv2.imread(\"neg/\" + str(img), cv2.IMREAD_GRAYSCALE)\n",
    "         \n",
    "            #Resize image to 60x160\n",
    "            resized_img = cv2.resize(gray_img, (200,200))\n",
    "            \n",
    "            \n",
    "            #Save image\n",
    "            cv2.imwrite(\"neg/\" + str(pic_num) + \".jpg\", resized_img)\n",
    "            \n",
    "            pic_num += 1\n",
    "print(\"resizing completed\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/Users/sarahhernandez/Documents/modeling-airplane-friction2.pem\n",
    " i-0175932a5d17320a8\n",
    "    ec2-54-193-93-136.us-west-1.compute.amazonaws.com\n",
    "    \n",
    "    password hash: sha1:a54879212232:fec7e50a5a6320daff99ad3b0c46c0fa25b97e75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = get_config()  # Get the config object.\n",
    "c.NotebookApp.certfile = u'/home/ubuntu/ssl/cert.pem' # path to the certificate we generated\n",
    "c.NotebookApp.keyfile = u'/home/ubuntu/ssl/cert.key' # path to the certificate key we generated\n",
    "c.IPKernelApp.pylab = 'inline'  # in-line figure when using Matplotlib\n",
    "c.NotebookApp.ip = '*'  # Serve notebooks locally.\n",
    "c.NotebookApp.open_browser = False  # Do not open a browser window by default when using notebooks.\n",
    "c.NotebookApp.password = 'sha1:a54879212232:fec7e50a5a6320daff99ad3b0c46c0fa25b97e75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
